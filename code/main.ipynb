{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def arr_averager(a):\n",
    "    for i in range(0,len(a)):\n",
    "        a[i] = a[i].mean()\n",
    "\n",
    "def find_fastest_line(line_dfs):\n",
    "    fastest_line = None\n",
    "    fastest_avg_runtime = float('inf')\n",
    "\n",
    "    for line, df in line_dfs.items():\n",
    "        if not df.empty and 'Average Actual Runtime' in df.columns:\n",
    "            avg_runtime = df['Average Actual Runtime'].mean()\n",
    "            if avg_runtime < fastest_avg_runtime:\n",
    "                fastest_avg_runtime = avg_runtime\n",
    "                fastest_line = line\n",
    "        elif df.empty:\n",
    "            print(f\"Warning: No data available for line {line} to calculate average runtime.\")\n",
    "        else:\n",
    "            print(f\"Warning: 'Average Actual Runtime' column not found for line {line}.\")\n",
    "\n",
    "    if fastest_line:\n",
    "        print(f\"The fastest line on average is line {fastest_line} with an average actual runtime of {fastest_avg_runtime:.2f} in minutes.\")\n",
    "    else:\n",
    "        print(\"No line data available with 'Average Actual Runtime' to determine the fastest line.\")\n",
    "    return fastest_line, fastest_avg_runtime\n",
    "\n",
    "def analyze_speed_trend(line_dfs, category_name):\n",
    "    fastest_line = None\n",
    "    fastest_avg_runtime = float('inf')\n",
    "    trends = {}\n",
    "\n",
    "    for line, df in line_dfs.items():\n",
    "        if not df.empty and 'Average Actual Runtime' in df.columns and 'Month' in df.columns:\n",
    "            try:\n",
    "                # Ensure 'Month' is treated as a numerical category\n",
    "                df['Month_numeric'] = pd.to_datetime(df['Month'],format='%m/01/%Y', errors='coerce').dt.month\n",
    "                df_cleaned = df.dropna(subset=['Month_numeric', 'Average Actual Runtime'])\n",
    "\n",
    "                if not df_cleaned.empty:\n",
    "                    X = df_cleaned['Month_numeric'].values.reshape(-1, 1)\n",
    "                    y = df_cleaned['Average Actual Runtime'].values\n",
    "                    model = LinearRegression()\n",
    "                    model.fit(X, y)\n",
    "                    slope = model.coef_[0]\n",
    "                    intercept = model.intercept_\n",
    "\n",
    "                    # Get the last month and corresponding runtime\n",
    "                    last_month = df_cleaned['Month_numeric'].iloc[-1]\n",
    "                    last_avg_runtime = df_cleaned['Average Actual Runtime'].iloc[-1]\n",
    "\n",
    "                    trends[line] = {'slope': slope, 'intercept': intercept, 'last_month': last_month, 'last_avg_runtime': last_avg_runtime}\n",
    "\n",
    "                    current_avg_runtime = df_cleaned['Average Actual Runtime'].mean()\n",
    "                    if current_avg_runtime < fastest_avg_runtime:\n",
    "                        fastest_avg_runtime = current_avg_runtime\n",
    "                        fastest_line = line\n",
    "                else:\n",
    "                    print(f\"Warning: Not enough valid data (Month and runtime) for linear regression on {category_name} line {line}.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during linear regression for {category_name} line {line}: {e}\")\n",
    "        elif df.empty:\n",
    "            print(f\"Warning: No data available for {category_name} line {line}.\")\n",
    "        else:\n",
    "            print(f\"Warning: Missing required columns ('Average Actual Runtime' or 'Month') for {category_name} line {line}.\")\n",
    "\n",
    "    print(f\"\\n--- Speed Trend Analysis (using 'Month' column) for {category_name} Lines ---\")\n",
    "    fastest_line_future_prediction = None\n",
    "    fastest_future_runtime = float('inf')\n",
    "\n",
    "    if fastest_line and trends:\n",
    "        print(f\"\\nCurrent fastest {category_name} line (based on overall average): {fastest_line} (Average Actual Runtime: {fastest_avg_runtime:.2f})\")\n",
    "\n",
    "        for line, trend in trends.items():\n",
    "            slope = trend['slope']\n",
    "            intercept = trend['intercept']\n",
    "            last_month = trend['last_month']\n",
    "            last_avg_runtime = trend['last_avg_runtime']\n",
    "            trend_desc = \"slowing down\" if slope > 0 else \"speeding up\" if slope < 0 else \"staying relatively constant\"\n",
    "            print(f\"Line {line}: Trend (per month): {trend_desc} (Slope: {slope:.8e}, Last Avg Runtime: {last_avg_runtime:.2f})\")\n",
    "\n",
    "            # Projecting to the next month (assuming monthly data)\n",
    "            future_month = last_month + 1\n",
    "            future_runtime = slope * future_month + intercept\n",
    "\n",
    "            if future_runtime < fastest_future_runtime:\n",
    "                fastest_future_runtime = future_runtime\n",
    "                fastest_line_future_prediction = line\n",
    "\n",
    "        if fastest_line_future_prediction:\n",
    "            print(f\"\\nBased on linear regression, the fastest {category_name} line in the next month (projected) might be: {fastest_line_future_prediction} (Projected Average Actual Runtime: {fastest_future_runtime:.2f})\")\n",
    "            if fastest_line_future_prediction == fastest_line:\n",
    "                print(f\"This suggests that the current fastest {category_name} line ({fastest_line}) is likely to remain the fastest.\")\n",
    "            else:\n",
    "                print(f\"This suggests a potential change in the fastest {category_name} line.\")\n",
    "        else:\n",
    "            print(f\"Could not predict the future fastest {category_name} line.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Could not determine the current fastest {category_name} line or analyze trends.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DEINTERLINED_TERMINI = {\n",
    "    '1': ['242ND STREET-BWAY', 'SOUTH FERRY TERMINAL'], #\n",
    "    '6': ['PELHAM BAY PARK', 'BROOKLYN BRIDGE'], # 6 exp and 6 loc have the same termini, just fewer stops on exp\n",
    "    '7': ['34TH STREET-HUDSON YARDS', 'FLUSHING-MAIN STREET'], # 7 exp and 7 loc have the same termini, just fewer stops on exp\n",
    "    'G': ['COURT SQUARE', 'CHURCH AVENUE'], #\n",
    "    'GS': ['TIMES SQUARE-SHUTTLE', 'GRAND CENTRAL-SHUTTLE'], # may exclude as its a major outlier\n",
    "    'FS': ['FRANKLIN AVENUE', 'PROSPECT PARK'], #\n",
    "    'H': ['BROAD CHANNEL', 'BEACH 116TH STREET-ROCKAWAY PARK', 'ROCKAWAY BOULEVARD', 'MOTT AVENUE-FAR ROCKAWAY'] # still known as the H in the database\n",
    "}\n",
    "INTERLINED_TERMINI = {\n",
    "    '2': ['EAST 241ST STREET', 'FLATBUSH AVENUE'], #\n",
    "    '3': ['148TH STREET-LENOX', 'NEW LOTS AVENUE'], #\n",
    "    '4': ['WOODLAWN-JEROME AVENUE', 'UTICA AVENUE'], #\n",
    "    '5': ['DYRE AVENUE', 'FLATBUSH AVENUE', 'EAST 238TH STREET'], #\n",
    "    'A': ['207TH STREET-8AV', 'LEFFERTS BOULEVARD-OZONE PARK', 'MOTT AVENUE-FAR ROCKAWAY', 'BEACH 116TH STREET-ROCKAWAY PARK'], #\n",
    "    'C': ['168TH STREET-8AV', 'EUCLID AVENUE'], #\n",
    "    'E': ['PARSONS/ARCHER-JAMAICA CENTER', 'WORLD TRADE CENTER'], #\n",
    "    'B': ['BEDFORD PARK BLVD', 'BRIGHTON BEACH'], #\n",
    "    'D': ['205TH STREET-NORWOOD', 'STILLWELL AVENUE-CONEY ISLAND'], #\n",
    "    'F': ['179TH STREET-JAMAICA', 'STILLWELL AVENUE-CONEY ISLAND'], #\n",
    "    'M': ['71ST/CONTINENTAL AVENUE-FOREST HILLS', 'METROPOLITAN AVENUE-MIDDLE VILLAGE'],\n",
    "    'N': ['STILLWELL AVENUE-CONEY ISLAND', 'DITMARS BOULEVARD-ASTORIA', 'WHITEHALL STREET-SOUTH FERRY'], # W is an N short turn in the database\n",
    "    'R': ['71ST/CONTINENTAL AVENUE-FOREST HILLS', '95TH STREET-BAY RIDGE'],\n",
    "    'Q': ['STILLWELL AVENUE-CONEY ISLAND', '96TH STREET-2AV'],\n",
    "    'J': ['PARSONS/ARCHER-JAMAICA CENTER', 'BROAD STREET'], # J and Z trips are the same, just some have fewer stops.\n",
    "}\n",
    "\n",
    "# dataset importing\n",
    "DATASET = pd.read_csv('../datasets/MTA_EtoE_Times.csv')\n",
    "\n",
    "# dataset cleaning\n",
    "DATASET = DATASET.drop(['Time Period', 'Schedule Day Type','Average Speed', 'Average Scheduled Runtime', 'Scheduled Trains', 'Actual Trains', 'Distance', 'Direction', 'Number of Stops', 'Stop Path ID', 'Origin Station ID', 'Destination Station ID',], axis=1)\n",
    "\n",
    "\n",
    "deinterlined_dataframes = {}\n",
    "interlined_dataframes = {}\n",
    "\n",
    "# Process deinterlined lines\n",
    "for line, termini in DEINTERLINED_TERMINI.items():\n",
    "    if len(termini) == 2:\n",
    "        origin, destination = termini\n",
    "        line_df = DATASET[((DATASET['Origin Station Name'] == origin) & (DATASET['Destination Station Name'] == destination)) |\n",
    "                           ((DATASET['Origin Station Name'] == destination) & (DATASET['Destination Station Name'] == origin))]\n",
    "        deinterlined_dataframes[line] = line_df\n",
    "    elif len(termini) > 2:\n",
    "        # Handle lines with multiple possible destinations (like the H line)\n",
    "        conditions = []\n",
    "        for i in range(len(termini)):\n",
    "            for j in range(i + 1, len(termini)):\n",
    "                origin, destination = termini[i], termini[j]\n",
    "                conditions.append(((DATASET['Origin Station Name'] == origin) & (DATASET['Destination Station Name'] == destination)) |\n",
    "                                  ((DATASET['Origin Station Name'] == destination) & (DATASET['Origin Station Name'] == origin)))\n",
    "        if conditions:\n",
    "            combined_condition = conditions[0]\n",
    "            for condition in conditions[1:]:\n",
    "                combined_condition = combined_condition | condition\n",
    "            line_df = DATASET[combined_condition]\n",
    "            deinterlined_dataframes[line] = line_df\n",
    "        else:\n",
    "            print(f\"Warning: No termini pairs found for deinterlined line {line}\")\n",
    "    else:\n",
    "        print(f\"Warning: Invalid number of termini for deinterlined line {line}\")\n",
    "\n",
    "# Process interlined lines\n",
    "for line, termini in INTERLINED_TERMINI.items():\n",
    "    conditions = []\n",
    "    # Handle lines with multiple possible termini\n",
    "    for origin in termini:\n",
    "        for destination in termini:\n",
    "            if origin != destination:\n",
    "                conditions.append(((DATASET['Origin Station Name'] == origin) & (DATASET['Destination Station Name'] == destination)) |\n",
    "                                  ((DATASET['Origin Station Name'] == destination) & (DATASET['Origin Station Name'] == origin)))\n",
    "    if conditions:\n",
    "        combined_condition = conditions[0]\n",
    "        for condition in conditions[1:]:\n",
    "            combined_condition = combined_condition | condition\n",
    "        line_df = DATASET[combined_condition]\n",
    "        interlined_dataframes[line] = line_df\n",
    "    else:\n",
    "        print(f\"Warning: No valid termini pairs found for interlined line {line}\")\n",
    "\n",
    "\n",
    "\n",
    "for line, df in deinterlined_dataframes.items():\n",
    "    df.drop(['Origin Station Name', 'Destination Station Name'], axis=1, inplace=True)\n",
    "\n",
    "for line, df in interlined_dataframes.items():\n",
    "    df.drop(['Origin Station Name', 'Destination Station Name'], axis=1, inplace=True)\n",
    "\n",
    "deinterlined_ns_dataframes = deinterlined_dataframes.copy()\n",
    "deinterlined_ns_dataframes.pop('GS')\n",
    "deinterlined_ns_dataframes.pop('FS')\n",
    "deinterlined_ns_dataframes.pop('H')\n",
    "\n",
    "\n",
    "# Find the fastest deinterlined line\n",
    "print(\"\\n--- Fastest Deinterlined Line ---\")\n",
    "fastest_deinterlined_line, fastest_deinterlined_runtime = find_fastest_line(deinterlined_dataframes)\n",
    "\n",
    "print(\"\\n--- Fastest Deinterlined Line (no shuttles) ---\")\n",
    "fastest_deinterlined_ns_line, fastest_deinterlined_ns_runtime = find_fastest_line(deinterlined_ns_dataframes)\n",
    "\n",
    "# Find the fastest interlined line\n",
    "print(\"\\n--- Fastest Interlined Line ---\")\n",
    "fastest_interlined_line, fastest_interlined_runtime = find_fastest_line(interlined_dataframes)\n",
    "\n",
    "\n",
    "# Analyze deinterlined lines\n",
    "analyze_speed_trend(deinterlined_dataframes, \"Deinterlined\")\n",
    "\n",
    "analyze_speed_trend(deinterlined_ns_dataframes, \"Deinterlined (No Shuttle)\")\n",
    "\n",
    "# Analyze interlined lines\n",
    "analyze_speed_trend(interlined_dataframes, \"Interlined\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
